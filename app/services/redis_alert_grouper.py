"""åŸºäº Redis çš„åˆ†å¸ƒå¼å‘Šè­¦åˆ†ç»„å™¨"""
import json
import time
from typing import List, Dict, Optional
from loguru import logger
import redis.asyncio as redis
from app.models.alert import AlertEvent, AlertRule


class RedisAlertGrouper:
    """Redis åˆ†å¸ƒå¼å‘Šè­¦åˆ†ç»„å™¨"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.group_wait = 10  # åˆ†ç»„ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        self.group_interval = 30  # åˆ†ç»„é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        self.repeat_interval = 3600  # é‡å¤å‘é€é—´éš”ï¼ˆç§’ï¼‰
        
        # Redis é”®å‰ç¼€
        self.firing_prefix = "alert:group:firing"
        self.recovery_prefix = "alert:group:recovery"
    
    def _get_group_key(self, group_key: str, is_recovery: bool = False) -> str:
        """ç”Ÿæˆåˆ†ç»„ Redis é”®"""
        prefix = self.recovery_prefix if is_recovery else self.firing_prefix
        return f"{prefix}:{group_key}"
    
    def _generate_group_key(self, alert: AlertEvent, rule: AlertRule) -> tuple:
        """
        ç”Ÿæˆåˆ†ç»„é”®
        
        è¿”å›: (group_key, group_labels)
        """
        group_by = rule.route_config.get('group_by', [])
        
        group_parts = [f"rule:{rule.name}"]
        group_labels = {"alertname": rule.name}
        
        for label_key in group_by:
            label_value = alert.labels.get(label_key, "")
            if label_value:
                group_parts.append(f"{label_key}:{label_value}")
                group_labels[label_key] = label_value
        
        group_key = "|".join(group_parts)
        return group_key, group_labels
    
    async def add_alert(self, alert: AlertEvent, rule: AlertRule) -> str:
        """
        æ·»åŠ å‘Šè­¦åˆ°åˆ†ç»„
        
        è¿”å›: group_key
        """
        logger.info(f"ğŸ”´ RedisAlertGrouper.add_alert è¢«è°ƒç”¨: fingerprint={alert.fingerprint[:16]}, rule={rule.name}")
        
        group_key, group_labels = self._generate_group_key(alert, rule)
        redis_key = self._get_group_key(group_key, is_recovery=False)
        
        logger.info(f"ğŸ”‘ Redisé”®: {redis_key}")
        
        # è·å–ç°æœ‰åˆ†ç»„æ•°æ®
        group_data = await self.redis.get(redis_key)
        current_time = time.time()
        
        if group_data:
            group = json.loads(group_data)
        else:
            # åˆ›å»ºæ–°åˆ†ç»„
            group = {
                "group_key": group_key,
                "group_labels": group_labels,
                "rule_id": rule.id,
                "rule_name": rule.name,
                "alerts": [],
                "created_at": current_time,
                "last_updated_at": current_time,
                "sent": False
            }
            logger.info(f"åˆ›å»ºæ–°çš„å‘Šè­¦åˆ†ç»„: {group_key}")
        
        # æ·»åŠ å‘Šè­¦ï¼ˆé¿å…é‡å¤ï¼‰
        alert_fingerprints = {a["fingerprint"] for a in group["alerts"]}
        if alert.fingerprint not in alert_fingerprints:
            group["alerts"].append({
                "fingerprint": alert.fingerprint,
                "rule_name": alert.rule_name,
                "severity": alert.severity,
                "value": alert.value,
                "labels": alert.labels,
                "annotations": alert.annotations,
                "started_at": alert.started_at,
                "expr": alert.expr,
                "tenant_id": alert.tenant_id
            })
            group["last_updated_at"] = current_time
            
            # ä¿å­˜åˆ° Redisï¼ˆè®¾ç½®è¿‡æœŸæ—¶é—´ä¸º 2 å°æ—¶ï¼‰
            await self.redis.setex(redis_key, 7200, json.dumps(group))
            logger.debug(f"å‘Šè­¦æ·»åŠ åˆ°åˆ†ç»„: {group_key}, å½“å‰å‘Šè­¦æ•°: {len(group['alerts'])}")
        
        return group_key
    
    async def add_recovery_alert(self, alert: AlertEvent, rule: AlertRule) -> str:
        """
        æ·»åŠ æ¢å¤å‘Šè­¦åˆ°åˆ†ç»„
        
        è¿”å›: group_key
        """
        group_key, group_labels = self._generate_group_key(alert, rule)
        recovery_key = f"recovery:{group_key}"
        redis_key = self._get_group_key(recovery_key, is_recovery=True)
        
        # è·å–ç°æœ‰åˆ†ç»„æ•°æ®
        group_data = await self.redis.get(redis_key)
        current_time = time.time()
        
        if group_data:
            group = json.loads(group_data)
        else:
            # åˆ›å»ºæ–°æ¢å¤åˆ†ç»„
            group = {
                "group_key": recovery_key,
                "group_labels": group_labels,
                "rule_id": rule.id,
                "rule_name": rule.name,
                "alerts": [],
                "created_at": current_time,
                "last_updated_at": current_time,
                "sent": False
            }
            logger.info(f"åˆ›å»ºæ–°çš„æ¢å¤å‘Šè­¦åˆ†ç»„: {recovery_key}")
        
        # æ·»åŠ æ¢å¤å‘Šè­¦
        alert_fingerprints = {a["fingerprint"] for a in group["alerts"]}
        if alert.fingerprint not in alert_fingerprints:
            group["alerts"].append({
                "fingerprint": alert.fingerprint,
                "rule_name": alert.rule_name,
                "severity": alert.severity,
                "value": alert.value,
                "labels": alert.labels,
                "annotations": alert.annotations,
                "started_at": alert.started_at,
                "expr": alert.expr,
                "tenant_id": alert.tenant_id
            })
            group["last_updated_at"] = current_time
            
            await self.redis.setex(redis_key, 7200, json.dumps(group))
            logger.debug(f"æ¢å¤å‘Šè­¦æ·»åŠ åˆ°åˆ†ç»„: {recovery_key}, å½“å‰å‘Šè­¦æ•°: {len(group['alerts'])}")
        
        return recovery_key
    
    async def get_ready_groups(self) -> List[tuple]:
        """
        è·å–å‡†å¤‡å¥½å‘é€çš„åˆ†ç»„
        
        è¿”å›: List[tuple(group_data, is_recovery)]
        """
        ready_groups = []
        current_time = time.time()
        
        # æ£€æŸ¥ firing åˆ†ç»„
        async for key in self.redis.scan_iter(match=f"{self.firing_prefix}:*", count=100):
            group_data = await self.redis.get(key)
            if group_data:
                group = json.loads(group_data)
                if self._is_group_ready(group, current_time):
                    ready_groups.append((group, False))
                    logger.info(f"âœ… firing åˆ†ç»„ç­‰å¾…æ—¶é—´å·²åˆ°: {group['group_key']}, å‘Šè­¦æ•°: {len(group['alerts'])}")
        
        # æ£€æŸ¥ recovery åˆ†ç»„
        async for key in self.redis.scan_iter(match=f"{self.recovery_prefix}:*", count=100):
            group_data = await self.redis.get(key)
            if group_data:
                group = json.loads(group_data)
                if self._is_group_ready(group, current_time):
                    ready_groups.append((group, True))
                    logger.info(f"âœ… recovery åˆ†ç»„ç­‰å¾…æ—¶é—´å·²åˆ°: {group['group_key']}, å‘Šè­¦æ•°: {len(group['alerts'])}")
        
        return ready_groups
    
    def _is_group_ready(self, group: dict, current_time: float) -> bool:
        """æ£€æŸ¥åˆ†ç»„æ˜¯å¦å‡†å¤‡å¥½å‘é€"""
        if not group.get("alerts"):
            return False
        
        if group.get("sent"):
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¤å‘é€
            if (current_time - group["last_updated_at"]) >= self.repeat_interval:
                return True
            return False
        
        # æ£€æŸ¥ç­‰å¾…æ—¶é—´
        wait_time = current_time - group["created_at"]
        return wait_time >= self.group_wait
    
    async def mark_group_sent(self, group_key: str, is_recovery: bool = False):
        """æ ‡è®°åˆ†ç»„ä¸ºå·²å‘é€"""
        redis_key = self._get_group_key(group_key, is_recovery)
        group_data = await self.redis.get(redis_key)
        
        if group_data:
            group = json.loads(group_data)
            group["sent"] = True
            await self.redis.setex(redis_key, 7200, json.dumps(group))
    
    async def clear_sent_group(self, group_key: str, is_recovery: bool = False):
        """æ¸…é™¤å·²å‘é€çš„åˆ†ç»„"""
        redis_key = self._get_group_key(group_key, is_recovery)
        await self.redis.delete(redis_key)
        logger.debug(f"æ¸…é™¤å·²å‘é€åˆ†ç»„: {group_key}")
    
    async def remove_alert_from_groups(self, fingerprint: str):
        """ä»æ‰€æœ‰åˆ†ç»„ä¸­ç§»é™¤æŒ‡å®šçš„å‘Šè­¦"""
        # æ‰«ææ‰€æœ‰ firing åˆ†ç»„
        async for key in self.redis.scan_iter(match=f"{self.firing_prefix}:*", count=100):
            group_data = await self.redis.get(key)
            if group_data:
                group = json.loads(group_data)
                original_count = len(group["alerts"])
                group["alerts"] = [a for a in group["alerts"] if a["fingerprint"] != fingerprint]
                
                if len(group["alerts"]) < original_count:
                    if group["alerts"]:
                        await self.redis.setex(key, 7200, json.dumps(group))
                    else:
                        await self.redis.delete(key)
    
    async def get_group_stats(self) -> Dict[str, int]:
        """è·å–åˆ†ç»„ç»Ÿè®¡ä¿¡æ¯"""
        firing_count = 0
        recovery_count = 0
        total_alerts = 0
        sent_count = 0
        pending_count = 0
        
        # ç»Ÿè®¡ firing åˆ†ç»„
        async for key in self.redis.scan_iter(match=f"{self.firing_prefix}:*", count=100):
            firing_count += 1
            group_data = await self.redis.get(key)
            if group_data:
                group = json.loads(group_data)
                total_alerts += len(group["alerts"])
                if group.get("sent"):
                    sent_count += 1
                else:
                    pending_count += 1
        
        # ç»Ÿè®¡ recovery åˆ†ç»„
        async for key in self.redis.scan_iter(match=f"{self.recovery_prefix}:*", count=100):
            recovery_count += 1
            group_data = await self.redis.get(key)
            if group_data:
                group = json.loads(group_data)
                total_alerts += len(group["alerts"])
                if group.get("sent"):
                    sent_count += 1
                else:
                    pending_count += 1
        
        return {
            "total_groups": firing_count + recovery_count,
            "firing_groups": firing_count,
            "recovery_groups": recovery_count,
            "total_alerts": total_alerts,
            "sent_groups": sent_count,
            "pending_groups": pending_count
        }
    
    def configure(
        self, 
        group_wait: int = 10, 
        group_interval: int = 30, 
        repeat_interval: int = 3600
    ):
        """é…ç½®åˆ†ç»„å‚æ•°"""
        self.group_wait = group_wait
        self.group_interval = group_interval
        self.repeat_interval = repeat_interval
        logger.info(
            f"Rediså‘Šè­¦åˆ†ç»„å™¨é…ç½®: group_wait={group_wait}s, "
            f"group_interval={group_interval}s, repeat_interval={repeat_interval}s"
        )

