"""å‘Šè­¦ç®¡ç†å™¨

è´Ÿè´£ç®¡ç†å‘Šè­¦çš„ç”Ÿå‘½å‘¨æœŸã€é™é»˜æ£€æŸ¥ã€é€šçŸ¥å‘é€å’Œå‘Šè­¦åˆ†ç»„ã€‚
"""
import time
import asyncio
from typing import List, Dict, Any, Optional
from loguru import logger
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.models.alert import AlertEvent, AlertEventHistory, AlertRule
from app.models.silence import SilenceRule
from app.services.notifier import NotificationService
from app.services.alert_grouper import AlertGrouper
from app.db.database import DatabaseSessionManager


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨
    
    è´Ÿè´£ç®¡ç†å‘Šè­¦çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸï¼ŒåŒ…æ‹¬ï¼š
    - å‘Šè­¦å‘é€å’Œé™é»˜æ£€æŸ¥
    - å‘Šè­¦åˆ†ç»„å’Œæ‰¹é‡å‘é€
    - å‘Šè­¦æ¢å¤é€šçŸ¥
    - å‘Šè­¦å½’æ¡£
    
    Attributes:
        db_manager: æ•°æ®åº“ä¼šè¯ç®¡ç†å™¨
        notifier: é€šçŸ¥æœåŠ¡
        grouper: å‘Šè­¦åˆ†ç»„å™¨ï¼ˆå†…å­˜ç‰ˆæœ¬ï¼‰
        _grouping_enabled: æ˜¯å¦å¯ç”¨å‘Šè­¦åˆ†ç»„
        _use_redis: æ˜¯å¦ä½¿ç”¨ Redis åˆ†ç»„å™¨
    """
    
    def __init__(self, use_redis: bool = True):
        """åˆå§‹åŒ–å‘Šè­¦ç®¡ç†å™¨
        
        Args:
            use_redis: æ˜¯å¦ä½¿ç”¨ Redis åˆ†ç»„å™¨ï¼Œé»˜è®¤ True
        """
        self.db_manager = DatabaseSessionManager()
        self.notifier = NotificationService()
        self._grouping_enabled = True  # æ˜¯å¦å¯ç”¨å‘Šè­¦åˆ†ç»„
        self._grouping_task = None
        self._use_redis = use_redis
        self._redis_grouper = None
        self._lock_manager = None
        self._redis_init_pending = use_redis  # æ ‡è®° Redis åˆå§‹åŒ–å¾…å¤„ç†
        
        # åˆå§‹åŒ–åˆ†ç»„å™¨ï¼ˆå†…å­˜ç‰ˆæœ¬ä½œä¸ºåå¤‡ï¼‰
        self.grouper = AlertGrouper()
    
    
    async def _init_redis_components(self):
        """å¼‚æ­¥åˆå§‹åŒ– Redis ç»„ä»¶"""
        if not self._redis_init_pending:
            logger.debug("Redis ç»„ä»¶å·²åˆå§‹åŒ–ï¼Œè·³è¿‡")
            return
        
        logger.info("å¼€å§‹åˆå§‹åŒ– Redis ç»„ä»¶...")
        
        try:
            from app.db.redis_client import RedisClient
            from app.services.redis_alert_grouper import RedisAlertGrouper
            from app.core.distributed_lock import AlertLockManager
            
            # å¼‚æ­¥è·å– Redis å®¢æˆ·ç«¯
            redis_client = await RedisClient.get_client()
            logger.info(f"Redis å®¢æˆ·ç«¯è·å–æˆåŠŸ: {redis_client}")
            
            # åˆå§‹åŒ– Redis åˆ†ç»„å™¨å’Œé”ç®¡ç†å™¨
            self._redis_grouper = RedisAlertGrouper(redis_client)
            self._lock_manager = AlertLockManager(redis_client)
            
            self._redis_init_pending = False
            logger.info(f"âœ… Redis åˆ†ç»„å™¨å’Œåˆ†å¸ƒå¼é”å·²å¯ç”¨ (grouper={self._redis_grouper}, lock={self._lock_manager})")
        except Exception as e:
            logger.warning(f"âš ï¸  Redis ç»„ä»¶åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜åˆ†ç»„å™¨: {str(e)}")
            logger.exception(e)
            self._use_redis = False
            self._redis_init_pending = False
    
    @property
    def active_grouper(self):
        """è·å–å½“å‰æ¿€æ´»çš„åˆ†ç»„å™¨"""
        is_redis = self._use_redis and self._redis_grouper is not None
        grouper = self._redis_grouper if is_redis else self.grouper
        grouper_type = "Redis" if is_redis else "Memory"
        logger.debug(f"ä½¿ç”¨{grouper_type}åˆ†ç»„å™¨ (use_redis={self._use_redis}, redis_grouper={self._redis_grouper is not None})")
        return grouper
    
    async def send_alert(self, alert: AlertEvent, rule: AlertRule):
        """å‘é€å‘Šè­¦é€šçŸ¥ï¼ˆæ”¯æŒåˆ†å¸ƒå¼é”ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦è¢«é™é»˜
            if await self.is_silenced(alert):
                logger.info(f"å‘Šè­¦è¢«é™é»˜: fingerprint={alert.fingerprint}")
                return
            
            # ä½¿ç”¨åˆ†å¸ƒå¼é”é˜²æ­¢é‡å¤å‘é€
            if self._lock_manager:
                # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å‘é€
                if await self._lock_manager.is_alert_sending(alert.fingerprint):
                    logger.debug(f"å‘Šè­¦æ­£åœ¨å‘é€ä¸­ï¼ˆåˆ†å¸ƒå¼é”ä¿æŠ¤ï¼‰: {alert.fingerprint}")
                    return
                
                # è·å–é”
                lock = self._lock_manager.get_alert_lock(alert.fingerprint, timeout=60)
                if not await lock.acquire(blocking=False):
                    logger.debug(f"æ— æ³•è·å–å‘Šè­¦é”ï¼Œè·³è¿‡: {alert.fingerprint}")
                    return
                
                try:
                    await self._send_alert_internal(alert, rule)
                finally:
                    await lock.release()
            else:
                await self._send_alert_internal(alert, rule)
            
        except Exception as e:
            logger.error(f"å‘é€å‘Šè­¦å¤±è´¥: fingerprint={alert.fingerprint}, error={str(e)}")
    
    async def _send_alert_internal(self, alert: AlertEvent, rule: AlertRule):
        """å†…éƒ¨å‘é€å‘Šè­¦é€»è¾‘"""
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å‘Šè­¦åˆ†ç»„
        enable_grouping = rule.route_config.get('enable_grouping', True)
        if self._grouping_enabled and enable_grouping:
            # ä½¿ç”¨åˆ†ç»„æ¨¡å¼
            current_time = int(time.time())
            if alert.last_sent_at > 0 and (current_time - alert.last_sent_at) < self.active_grouper.group_wait + 5:
                logger.debug(f"å‘Šè­¦å·²åœ¨åˆ†ç»„ä¸­ï¼Œè·³è¿‡: {alert.fingerprint}")
                return
            
            # æ·»åŠ åˆ°åˆ†ç»„å™¨
            await self.active_grouper.add_alert(alert, rule)
            logger.info(f"å‘Šè­¦å·²æ·»åŠ åˆ°åˆ†ç»„å™¨: {alert.fingerprint}")
            
            # æ ‡è®°ä¸ºå·²å¤„ç†ï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
            async with self.db_manager.session() as db:
                alert.last_sent_at = current_time
        else:
            # ç›´æ¥å‘é€ï¼ˆä¸åˆ†ç»„ï¼‰
            if not self.should_send_notification(alert):
                logger.debug(f"æœªåˆ°é€šçŸ¥é—´éš”: fingerprint={alert.fingerprint}")
                return
            
            await self.notifier.send_notification(alert, rule, is_recovery=False)
            
            # æ›´æ–°æœ€åå‘é€æ—¶é—´
            async with self.db_manager.session() as db:
                alert.last_sent_at = int(time.time())
    
    async def send_recovery(self, alert: AlertEvent, rule: AlertRule):
        """å‘é€æ¢å¤é€šçŸ¥"""
        try:
            # ä» firing åˆ†ç»„å™¨ä¸­ç§»é™¤è¯¥å‘Šè­¦
            await self.active_grouper.remove_alert_from_groups(alert.fingerprint)
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ¢å¤å‘Šè­¦åˆ†ç»„
            enable_grouping = rule.route_config.get('enable_grouping', True)
            enable_recovery_grouping = rule.route_config.get('enable_recovery_grouping', True)
            
            if self._grouping_enabled and enable_grouping and enable_recovery_grouping:
                # æ·»åŠ åˆ°æ¢å¤å‘Šè­¦åˆ†ç»„å™¨
                await self.active_grouper.add_recovery_alert(alert, rule)
                logger.info(f"æ¢å¤å‘Šè­¦å·²æ·»åŠ åˆ°åˆ†ç»„å™¨: {alert.fingerprint}")
            else:
                # ç›´æ¥å‘é€æ¢å¤é€šçŸ¥
                await self.notifier.send_notification(alert, rule, is_recovery=True)
            
        except Exception as e:
            logger.error(f"å‘é€æ¢å¤é€šçŸ¥å¤±è´¥: fingerprint={alert.fingerprint}, error={str(e)}")
    
    async def is_silenced(self, alert: AlertEvent) -> bool:
        """æ£€æŸ¥å‘Šè­¦æ˜¯å¦è¢«é™é»˜"""
        from app.services.silence_matcher import check_silence_match
        
        current_time = int(time.time())
        
        # ä½¿ç”¨ç‹¬ç«‹ä¼šè¯æŸ¥è¯¢ç”Ÿæ•ˆçš„é™é»˜è§„åˆ™
        async with self.db_manager.session(auto_commit=False) as db:
            # æŸ¥è¯¢ç”Ÿæ•ˆçš„é™é»˜è§„åˆ™
            stmt = select(SilenceRule).where(
                SilenceRule.tenant_id == alert.tenant_id,
                SilenceRule.is_enabled == True,
                SilenceRule.starts_at <= current_time,
                SilenceRule.ends_at >= current_time
            )
            result = await db.execute(stmt)
            silence_rules = result.scalars().all()
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…é™é»˜è§„åˆ™ï¼ˆä½¿ç”¨æ–°çš„åŒ¹é…é€»è¾‘ï¼‰
        for rule in silence_rules:
            if check_silence_match(alert.labels, rule.matchers):
                logger.info(f"å‘Šè­¦åŒ¹é…é™é»˜è§„åˆ™: fingerprint={alert.fingerprint}, silence_rule={rule.name}")
                return True
        
        return False
    
    @staticmethod
    def should_send_notification(alert: AlertEvent, min_interval: int = 300) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‘é€é€šçŸ¥ï¼ˆåŸºäºæ—¶é—´é—´éš”ï¼‰"""
        if alert.last_sent_at == 0:
            return True
        
        current_time = int(time.time())
        return (current_time - alert.last_sent_at) >= min_interval
    
    async def archive_alert(self, alert: AlertEvent):
        """å½’æ¡£å‘Šè­¦åˆ°å†å²"""
        try:
            # é‡æ–°æŸ¥è¯¢å‘Šè­¦å¯¹è±¡(é¿å…ä¼šè¯å†²çª)
            stmt = select(AlertEvent).where(AlertEvent.fingerprint == alert.fingerprint)
            result = await self.db.execute(stmt)
            db_alert = result.scalar_one_or_none()
            
            if not db_alert:
                logger.warning(f"å‘Šè­¦ä¸å­˜åœ¨,æ— éœ€å½’æ¡£: {alert.fingerprint}")
                return
            
            # åˆ›å»ºå†å²è®°å½•
            history = AlertEventHistory(
                fingerprint=db_alert.fingerprint,
                rule_id=db_alert.rule_id,
                rule_name=db_alert.rule_name,
                status=db_alert.status,
                severity=db_alert.severity,
                started_at=db_alert.started_at,
                resolved_at=int(time.time()),
                duration=int(time.time()) - db_alert.started_at,
                value=db_alert.value,
                labels=db_alert.labels,
                annotations=db_alert.annotations,
                expr=db_alert.expr,
                tenant_id=db_alert.tenant_id,
                project_id=db_alert.project_id
            )
            
            self.db.add(history)
            
            # åˆ é™¤å½“å‰å‘Šè­¦
            await self.db.delete(db_alert)
            await self.db.commit()
            
        except Exception as e:
            await self.db.rollback()
            logger.error(f"å½’æ¡£å‘Šè­¦å¤±è´¥: fingerprint={alert.fingerprint}, error={str(e)}")
    
    async def start_grouping_worker(self):
        """å¯åŠ¨å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨ï¼ˆåå°ä»»åŠ¡ï¼‰"""
        if self._grouping_task is not None:
            logger.warning("å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨å·²åœ¨è¿è¡Œ")
            return
        
        # å…ˆåˆå§‹åŒ– Redis ç»„ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self._redis_init_pending:
            await self._init_redis_components()
        
        self._grouping_task = asyncio.create_task(self._grouping_worker())
        logger.info("å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨å·²å¯åŠ¨")
    
    async def stop_grouping_worker(self):
        """åœæ­¢å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨"""
        if self._grouping_task:
            self._grouping_task.cancel()
            try:
                await self._grouping_task
            except asyncio.CancelledError:
                pass
            self._grouping_task = None
            logger.info("å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨å·²åœæ­¢")
    
    async def _grouping_worker(self):
        """
        å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨ï¼ˆå®šæœŸæ£€æŸ¥å¹¶å‘é€å‡†å¤‡å¥½çš„åˆ†ç»„ï¼‰
        
        å‚è€ƒ Alertmanager çš„é€»è¾‘ï¼š
        1. æ¯éš”ä¸€æ®µæ—¶é—´æ£€æŸ¥åˆ†ç»„
        2. group_wait: é¦–æ¬¡ç­‰å¾…æ—¶é—´
        3. group_interval: å·²å‘é€åˆ†ç»„çš„é‡å¤é—´éš”
        4. repeat_interval: æŒç»­å‘Šè­¦çš„é‡å¤å‘é€é—´éš”
        """
        logger.info("ğŸš€ å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨å¼€å§‹è¿è¡Œ")
        iteration = 0
        
        while True:
            try:
                iteration += 1
                
                # æ¯10æ¬¡è¿­ä»£è¾“å‡ºä¸€æ¬¡å¿ƒè·³ï¼ˆ50ç§’ï¼‰
                if iteration % 10 == 0:
                    logger.info(f"ğŸ’“ åˆ†ç»„å·¥ä½œå™¨å¿ƒè·³æ£€æŸ¥ (è¿­ä»£: {iteration})")
                
                # è·å–åˆ†ç»„ç»Ÿè®¡
                stats = await self.get_grouping_stats()
                logger.debug(f"ğŸ” å½“å‰åˆ†ç»„ç»Ÿè®¡: {stats}")
                if stats.get('total_groups', 0) > 0:
                    logger.info(f"ğŸ“Š åˆ†ç»„ç»Ÿè®¡: {stats}")
                
                # è·å–å‡†å¤‡å¥½å‘é€çš„åˆ†ç»„
                ready_groups = await self.active_grouper.get_ready_groups()
                
                if ready_groups:
                    logger.info(f"ğŸ¯ æ£€æµ‹åˆ° {len(ready_groups)} ä¸ªå‡†å¤‡å¥½çš„åˆ†ç»„")
                
                # å‘é€æ¯ä¸ªå‡†å¤‡å¥½çš„åˆ†ç»„
                for group, is_recovery in ready_groups:
                    try:
                        await self._send_alert_group(group, is_recovery)
                    except Exception as e:
                        # å…¼å®¹å¯¹è±¡å’Œå­—å…¸æ ¼å¼
                        group_key = group.get('group_key') if isinstance(group, dict) else getattr(group, 'group_key', 'unknown')
                        logger.error(f"âŒ å‘é€å‘Šè­¦åˆ†ç»„å¤±è´¥: group={group_key}, is_recovery={is_recovery}, error={str(e)}")
                        import traceback
                        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                
                # æ¯éš”5ç§’æ£€æŸ¥ä¸€æ¬¡ï¼ˆç±»ä¼¼ Alertmanager çš„ check intervalï¼‰
                await asyncio.sleep(5)
                
            except asyncio.CancelledError:
                logger.info("ğŸ›‘ å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"âŒ å‘Šè­¦åˆ†ç»„å·¥ä½œå™¨é”™è¯¯: {str(e)}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                await asyncio.sleep(5)  # å‘ç”Ÿé”™è¯¯æ—¶ç­‰å¾…åé‡è¯•
    
    async def _send_alert_group(self, group, is_recovery: bool = False):
        """å‘é€å‘Šè­¦åˆ†ç»„ï¼ˆæ”¯æŒå¯¹è±¡å’Œå­—å…¸æ ¼å¼ï¼‰
        
        Args:
            group: å‘Šè­¦åˆ†ç»„å¯¹è±¡æˆ–å­—å…¸
            is_recovery: æ˜¯å¦ä¸ºæ¢å¤å‘Šè­¦
        """
        # ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
        async with self.db_manager.session() as db:
            try:
                # å…¼å®¹å¯¹è±¡å’Œå­—å…¸ä¸¤ç§æ ¼å¼
                if isinstance(group, dict):
                    # Redis åˆ†ç»„å™¨è¿”å›å­—å…¸
                    alerts_data = group.get('alerts', [])
                    group_key = group.get('group_key')
                    rule_id = group.get('rule_id')
                    
                    if not alerts_data:
                        logger.warning(f"åˆ†ç»„ä¸ºç©º: {group_key}")
                        return
                    
                    # æŸ¥è¯¢è§„åˆ™å¯¹è±¡
                    stmt = select(AlertRule).where(AlertRule.id == rule_id)
                    result = await db.execute(stmt)
                    rule = result.scalar_one_or_none()
                    
                    if not rule:
                        logger.warning(f"åˆ†ç»„æ²¡æœ‰å…³è”çš„è§„åˆ™: {group_key}")
                        return
                    
                    # å°†å­—å…¸æ•°æ®è½¬æ¢ä¸º AlertEvent å¯¹è±¡åˆ—è¡¨ï¼ˆç”¨äºå‘é€ï¼‰
                    alerts = []
                    for alert_data in alerts_data:
                        # ä»æ•°æ®åº“æŸ¥è¯¢å®Œæ•´çš„ AlertEvent å¯¹è±¡
                        stmt = select(AlertEvent).where(AlertEvent.fingerprint == alert_data['fingerprint'])
                        result = await db.execute(stmt)
                        alert_obj = result.scalar_one_or_none()
                        if alert_obj:
                            alerts.append(alert_obj)
                    
                else:
                    # å†…å­˜åˆ†ç»„å™¨è¿”å›å¯¹è±¡
                    alerts = group.get_alerts()
                    group_key = group.group_key
                    rule = group.rule
                    
                    if not alerts:
                        logger.warning(f"åˆ†ç»„ä¸ºç©º: {group_key}")
                        return
                    
                    if not rule:
                        logger.warning(f"åˆ†ç»„æ²¡æœ‰å…³è”çš„è§„åˆ™: {group_key}")
                        return
                
                status_text = "æ¢å¤" if is_recovery else "å‘Šè­¦"
                logger.info(f"â­ å‘é€{status_text}åˆ†ç»„: {group_key}, å‘Šè­¦æ•°: {len(alerts)}")
                
                # æ‰¹é‡å‘é€å‘Šè­¦
                await self.notifier.send_batch_notification(alerts, rule, is_recovery=is_recovery)
                
                # æ›´æ–°æ‰€æœ‰å‘Šè­¦çš„æœ€åå‘é€æ—¶é—´
                current_time = int(time.time())
                for alert in alerts:
                    try:
                        # é‡æ–°æŸ¥è¯¢å¯¹è±¡ä»¥ç¡®ä¿åœ¨å½“å‰ä¼šè¯ä¸­
                        stmt = select(AlertEvent).where(AlertEvent.fingerprint == alert.fingerprint)
                        result = await db.execute(stmt)
                        db_alert = result.scalar_one_or_none()
                        if db_alert:
                            db_alert.last_sent_at = current_time
                    except Exception as e:
                        logger.warning(f"æ›´æ–°å‘Šè­¦å‘é€æ—¶é—´å¤±è´¥: {alert.fingerprint}, error={str(e)}")
                
                logger.info(f"âœ… {status_text}åˆ†ç»„å‘é€æˆåŠŸ: {group_key}")
                
                # æ ‡è®°åˆ†ç»„ä¸ºå·²å‘é€ï¼ˆå¯¹è±¡æ ¼å¼æ‰éœ€è¦ï¼‰
                if not isinstance(group, dict) and hasattr(group, 'mark_sent'):
                    group.mark_sent()
                
                # æ¸…ç†å·²å‘é€çš„åˆ†ç»„
                await self.active_grouper.clear_sent_group(group_key, is_recovery)
                
            except Exception as e:
                group_key = group.get('group_key') if isinstance(group, dict) else getattr(group, 'group_key', 'unknown')
                logger.error(f"âŒ å‘é€å‘Šè­¦åˆ†ç»„å¤±è´¥: {group_key}, error={str(e)}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                # ä¸å†é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…ä¸­æ–­åˆ†ç»„å·¥ä½œå™¨
    
    def configure_grouper(
        self, 
        group_wait: int = 10, 
        group_interval: int = 30, 
        repeat_interval: int = 3600
    ):
        """é…ç½®å‘Šè­¦åˆ†ç»„å™¨å‚æ•°"""
        self.grouper.configure(group_wait, group_interval, repeat_interval)
        if self._redis_grouper:
            self._redis_grouper.configure(group_wait, group_interval, repeat_interval)
    
    def enable_grouping(self, enabled: bool = True):
        """å¯ç”¨æˆ–ç¦ç”¨å‘Šè­¦åˆ†ç»„"""
        self._grouping_enabled = enabled
        logger.info(f"å‘Šè­¦åˆ†ç»„å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}")
    
    async def get_grouping_stats(self) -> Dict[str, int]:
        """è·å–å‘Šè­¦åˆ†ç»„ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if self._use_redis and self._redis_grouper:
                return await self.active_grouper.get_group_stats()
            else:
                return self.grouper.get_group_stats()
        except Exception as e:
            logger.debug(f"è·å–åˆ†ç»„ç»Ÿè®¡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {str(e)}")
            # å›é€€åˆ°å†…å­˜åˆ†ç»„å™¨
            return self.grouper.get_group_stats()

